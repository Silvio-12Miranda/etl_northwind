<div align="center">
  <h1>ETL Northwind - Prueba T√©cnica</h1>
</div>
Este repositorio contiene la soluci√≥n de la prueba t√©cnica para la implementaci√≥n de un proceso ETL utilizando **Python, Polars y PostgreSQL**.

## Requisitos

Antes de ejecutar el proyecto, aseg√∫rate de tener instalados los siguientes requisitos:

### Tecnolog√≠as utilizadas
- **Docker**
- **Python 3.8+**
- **PostgreSQL**
- **SQLAlchemy**
- **Polars**
- **Psycopg2**

### Instalaci√≥n de dependencias
Ejecuta el siguiente comando para instalar todas las dependencias:

```bash
pip install -r requirements.txt
```
## SOLUCIONES:

## 1. Modelado de Data Warehouse

El modelo de datos utilizado en esta prueba t√©cnica sigue un esquema en estrella. Este dise√±o es ampliamente utilizado en Data Warehouses debido a su eficiencia en consultas anal√≠ticas y de agregaci√≥n.

### Tablas del modelo

Tabla de Hechos:
- **VENTAS (Ventas registradas con m√©tricas de cantidad y precio total).**

Tablas de Dimensiones:
- **D_TIEMPO (Dimensi√≥n de tiempo con granularidad de fecha, mes y a√±o).**
- **D_CLIENTES (Informaci√≥n de clientes).**
- **D_PRODUCTOS (Informaci√≥n de productos y sus categor√≠as).**
- **D_CATEGORIAS (Categor√≠as de productos).**
- **D_EMPLEADOS (Vendedores y empleados involucrados en ventas).**
- **D_REGIONES (Regiones donde ocurren las ventas).**

Ahora bien la justificacion por el cual se utilizo este tipo de esquema de estrella es el siguiente:
- Tiene un mejor rendimiento en consultas.
- Permite una r√°pida agregaci√≥n y an√°lisis de datos en herramientas de BI.
- El que este desnormalizada evita cruces costosos en memoria.

<div align="center">
  <h1>MODELO ESTRELLA DWH</h1>
</div>

<div align="center"> 
  <img src="imagenes/modelo_estrella.jpg" width="700">
</div>

## 2. Desarrollo de ETL 

Se monto un contenedor con postgreSQL utilizando Docker-compose para poder tener la permanencia de los datos en el servidor, el YAML contine las configuraciones necesarias para poder crear un contenedor con postgreSQL.

<div align="center"> 
  <img src="imagenes/contenedor_activo.jpg" width="700">
</div>

 
```
version: '3.8'

services:
  postgres:
    image: postgres:latest
    container_name: postgres_silvio
    restart: always
    environment:
      POSTGRES_USER: silvioMiranda
      POSTGRES_PASSWORD: Smirlop
      POSTGRES_DB: mydatabase
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

volumes:
  postgres_data:
```

Con pgAdmin visualizamos las estructuras de datos que se crearon a partir del Modelo **Northwind_DWH**

<div align="center"> 
  <img src="imagenes/modelo_creado.jpg" width="700">
</div>


## 3. Business Intelligence

Las siguientes consultas resuelven toda la seccion 3.

```sql
-- ¬øQu√© categor√≠a present√≥ las mejores ventas durante el a√±o 2016?
SELECT c."CategoryName", SUM(v."Total_Venta") AS total_ventas
FROM public."VENTAS" v
JOIN public."D_PRODUCTOS" p ON v."ProductID" = p."ProductID"
JOIN public."D_CATEGORIAS" c ON p."CategoryID" = c."CategoryID"
JOIN public."D_TIEMPO" t ON v."OrderDate" = t."Fecha"
WHERE t."A√±o" = 2016
GROUP BY c."CategoryName"
ORDER BY total_ventas DESC
LIMIT 1;
```
<div align="center"> 
  <img src="imagenes/sql1.jpg" width="700">
</div>

```sql
-- ¬øCu√°l fue el empleado con mejor promedio de ventas diarias (en dinero) en el a√±o 2020?
SELECT e."Nombre_Empleado", AVG(v."Total_Venta") AS promedio_ventas_diarias
FROM public."VENTAS" v
JOIN public."D_EMPLEADOS" e ON v."EmployeeID" = e."EmployeeID"
JOIN public."D_TIEMPO" t ON v."OrderDate" = t."Fecha"
WHERE t."A√±o" = 2020
GROUP BY e."Nombre_Empleado"
ORDER BY promedio_ventas_diarias DESC
LIMIT 1;
```
<div align="center"> 
  <img src="imagenes/sql2.jpg" width="700">
</div>

```sql
-- ¬øCu√°l fue el d√≠a con mayor cantidad de ventas (en cantidad de operaciones) durante el primer semestre de 2015?
SELECT t."Fecha", COUNT(v."OrderID") AS cantidad_ventas
FROM public."VENTAS" v
JOIN public."D_TIEMPO" t ON v."OrderDate" = t."Fecha"
WHERE t."A√±o" = 2015 AND t."Mes" BETWEEN 1 AND 6
GROUP BY t."Fecha"
ORDER BY cantidad_ventas DESC
LIMIT 1;
```
<div align="center"> 
  <img src="imagenes/sql3.jpg" width="700">
</div>


```sql
-- Hist√≥ricamente, ¬øcu√°l es el mejor cliente que ha tenido la empresa?
SELECT c."Nombre_Cliente", SUM(v."Total_Venta") AS total_gastado
FROM public."VENTAS" v
JOIN public."D_CLIENTES" c ON v."CustomerID" = c."CustomerID"
GROUP BY c."Nombre_Cliente"
ORDER BY total_gastado DESC
LIMIT 1;
```
<div align="center"> 
  <img src="imagenes/sql4.jpg" width="700">
</div>





## Configuraci√≥n

1. **Configurar la base de datos**
   
   Crea una base de datos en PostgreSQL:
   ```sql
   CREATE DATABASE northwind;
   ```

2. **Configurar las credenciales de la base de datos**
   
   Modifica el archivo `etl_northwind/config.py` con las credenciales correctas:
   ```python
   DATABASE_CONFIG = {
       'dbname': 'northwind',
       'user': 'tu_usuario',
       'password': 'tu_contrase√±a',
       'host': 'localhost',
       'port': '5432'
   }
   ```

3. **Verificar la existencia del script SQL**
   
   Aseg√∫rate de que el archivo `Northwind.sql` se encuentra en:
   ```
   postgres-docker/scripts/Northwind.sql
   ```

   Este archivo contiene la estructura de las tablas y se ejecutar√° autom√°ticamente al iniciar el ETL.

## üèóÔ∏è Estructura del Proyecto

```
üìÇ etl_northwind
 ‚îú‚îÄ‚îÄ config.py             # Configuraci√≥n de la base de datos
 ‚îú‚îÄ‚îÄ execute_sql.py        # Creaci√≥n de tablas en PostgreSQL
 ‚îú‚îÄ‚îÄ extract.py            # Extracci√≥n de datos desde SQLite
 ‚îú‚îÄ‚îÄ transform.py          # Transformaci√≥n de datos usando Polars
 ‚îú‚îÄ‚îÄ load_data.py          # Carga de datos en PostgreSQL
 ‚îú‚îÄ‚îÄ main.py               # Ejecuci√≥n del proceso ETL
 ‚îú‚îÄ‚îÄ requirements.txt      # Dependencias del proyecto
```

## Ejecuci√≥n del ETL

Para ejecutar el proceso ETL, usa el siguiente comando:

```bash
python -m etl_northwind.main
```

El proceso se ejecutar√° en los siguientes pasos:

1Ô∏è**[Paso 1] Creaci√≥n de tablas**: Se verifican y crean las tablas si no existen.

2Ô∏è**[Paso 2] Extracci√≥n de datos**: Se extraen datos desde la base de datos.

3Ô∏è**[Paso 3] Transformaci√≥n de datos**: Se transforman los datos evitando duplicados.

4Ô∏è**[Paso 4] Carga de datos**: Se insertan solo los datos nuevos en PostgreSQL.
